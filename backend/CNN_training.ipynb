{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "a0231fd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import PIL\n",
    "import PIL.Image\n",
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "import pathlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "011d8854",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "28709\n"
     ]
    }
   ],
   "source": [
    "data_dir = pathlib.Path('data/train/').with_suffix('')\n",
    "image_count = len(list(data_dir.glob('*/*.jpg')))\n",
    "print(image_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "8a19ce91",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/jpeg": "/9j/4AAQSkZJRgABAQAAAQABAAD/2wBDAAgGBgcGBQgHBwcJCQgKDBQNDAsLDBkSEw8UHRofHh0aHBwgJC4nICIsIxwcKDcpLDAxNDQ0Hyc5PTgyPC4zNDL/wAALCAAwADABAREA/8QAHwAAAQUBAQEBAQEAAAAAAAAAAAECAwQFBgcICQoL/8QAtRAAAgEDAwIEAwUFBAQAAAF9AQIDAAQRBRIhMUEGE1FhByJxFDKBkaEII0KxwRVS0fAkM2JyggkKFhcYGRolJicoKSo0NTY3ODk6Q0RFRkdISUpTVFVWV1hZWmNkZWZnaGlqc3R1dnd4eXqDhIWGh4iJipKTlJWWl5iZmqKjpKWmp6ipqrKztLW2t7i5usLDxMXGx8jJytLT1NXW19jZ2uHi4+Tl5ufo6erx8vP09fb3+Pn6/9oACAEBAAA/AK/gnTbXTdLtWjhXz2QPLIRySea9CtSH25/lWuJDFGqgHBOaguSu4tnqOlcb4r0tNSsZopF3Ky8cfyrzLwvoOr6vqa2VhG8zHOc4wvqWPYV3OmSC20e1nZSFMAZgoycY7e9aFn400y0kWO+tbuwJHBuVOGrsbXUrG6t0khlDxtypBqjrWv2umWjSLEZpf4UB5Ncva67e6rcqJrrT8BubVH3OB2yR0PtXqPg+zgs/DltHDDHGfm3lFxuO48n1NeZwW01n4csfLTM8cC8EZwa5jUrbWb1rVZ5rmf7RIRc+XsVLZM4HykZY45J/D3rY8BWmtW13Il4Ek05MhJNpG49sA9Kv+J/Dtxe3xmW43W7oVSFSAQ+DyR/Fg4OKr6R4eufIs4ruPzbm1Ztt40CxsVOPlODyB2z612GgzXdr44htxIzW09myyRg8KynKv+WRWZpatDpsH2sDzQCrqFwByTjH0Iq9c2dh9mNzLEuEG7n2rjU8Vpp175lzFKouWBRADtCfwjPY/wCNWZfEA1q+igto2hlU+ZHJuyIz/wDX9PeuksNZSa1JmUJcKdrqOzDrXQ+GI0uL+W7YZlSLYD7E5/pWP4m07+ybhDESbebLLkfcI/h/lXDeJdXnt9IZI2JaaRYgPqef0zUMOmNrreStrLcONqF0IVUJIGNx4649akutKh8Mwma5W1g3Kww2oR7xtIGAOPXtUeiX63GoSSRSeZa3MIljcnuOP/rfhXrfguB1sZ526O4RfoB/9erniiyF/oNxtXdLCPNj+o6j8RmvFtV8ue1ZyOI3SQZ/KvL4LS+n1a8t55nDQyswjeUgZLdQOnpUl34b3QSSbkWUdEHzMzenFdt4Nt5NN0i0juQwkKSHaeq5YcV794euoo9FtYQpVwmSCOpJNf/Z",
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAADAAAAAwCAAAAAByaaZbAAAHSUlEQVR4ARWWW29cVxmGv3XexznZY48dO87BCXFJ3CaCIESrUApUAiQukACJSy7an8AFXCLEHfwAJH4AVy0CIY5CoRRCRGlLcBMf4lNsx/HYM3v23mvtdWL5ZjTaM5/WvO/3rucdlNpsYWVlvschAuNwIlzaAemxk1obFN7B6XC4+zvVRxmnMbE0lndW56ZjjrD3VGCKMRhvsXfEW0CYG0NYPnP18RnRcdtFlBYLrw2UQpQ7i5winlOnXcOBgrYIO4fPx7Lro21WpUWnLWh0c7E0DJzBhCCEMWIegfUQvkcgHKocIhhPLxcYNCNW0+5CPU6dkYJbzwX1GHlnGoSpdZSFw4jwEbLQxcQKxlhG07gOs9wTDMgbTpyzqlGOJJ54Z43RYSiBcRo74Tj0vkBjO6EuxqAsjawlMSbIIYaQZlSVGjlmKPWe8bRKmer/4CbNkSUey5gRQij4KkXUUOQwMUpZAZXxEZbQ5XmtOp/5/hVDOSUUEeoUhrrFrZA6DqIxeOegpaoUE6+Q1O3p6o2vrQgbfE8iRCxS1sTRWLTCxuy5EE+UEMp3sdEEKHU5f+tbxDbMh0XFRhFG81ZCECXBq6AeY+xzb3Or63KsdtScsLMt0nAEQK20VFvTmk47ExsZOF85EmHTAAykOnv85Awf9b6YdE/AG+QJHQN3vkj51jBP0w61eVgZDekAFsx9trFz/DS+s3L4NG1JEA6Do5jRinv83r8bvnB1oScUF2ANMG29q/fWHtPbd2K2+kJ1mjoO5mHqRWYlDLfYzOi/a/3Z7NLCLA7uW6elLHfHc1eX1JiwNlVkci4BKBPeYS9vX0Fy+9HObrJ7GwSnZgISTl6QRXl0f6+9PD9YTELWHPJAVYhvNOkvJrp66crT9aPJQWvW8oz4ejSW9iPT/xL7zfsvZxXrvl9/g1lKSR01iseonuxt1wTNVMfOLia8e8Lo2fHD6anT/be/+0PNtG/8u8dveUcRy6qG60/Ojh4cL/PyWWe2MfpWArn728bj7rd/Pvnn+Mevf+wR8elu9b3c0Sj1iI9Ojg4+vPTTfzy8sfrr562j4zTrW59VryyT3m7a+9fZUgNQ0SsbW6uG+lykcmxxNPej9V/0n/5k9p1y0u4lLoLPWfkcf/XrCd1CebsV13Jl/clNREW4CIZGmN81G/ZJb39qdRhdbEHFae/1nZNKNkNDeridxwR6s0+xo68wA0R08Hz98dLb3pabrelbV32dhSD0SOQnwcU0TuPMCzeZZ2DpLAoHpBiTutCDCB3Px4OFblkir3i5U1xoQ2QoQ8Ecb0/Tm47R/bxRkeCRabUKu6+yxbx8dKUtAj+M0w/al01QgyDGnkC/uBwmB6ahgtFEkYSUrXTWmr0XAxse6dplnb+3pwJoaKCAtGLWdZGn7n9LunFx1NLQduCIOlm71agOz+nIkJt/vv9q7gVmpgBF2tACRO8TFowiXuMIKa+9fYi7J5xPDRF50SSf+uSDlRnsyAQ1ukbLWBOavRxwZS3lyCLqdf1o7dNInj3f9xOXyrP28k6HpK1Cehm8mT9P60JcZ0rhRmUUI2WGaxebB2M2dWBxe3370r0Zs8t6WLsKCe9DkjxemIyIlk0TTrFem6NqJj366A/vmYYN1xcviGy5LOvDamytc0b7oOG6HGvnqxg09aaWh1lPLSF7eBDRsyUBBYumthJSMxPADpwEqu33mdVh2tcq00V5Ns8lUWx+6EftMaDTBnfWDy9YwMb4gCDi6cVxxUOTKKJ1sG5vdHFY4UvVMIpoxS4Pil0qYHsJhR/hPSHnHXL3XWOD/Y1ujMV6vSpwI6aUUzPQxJ0x7dgCNm8MEApgoMIHl8S9h6fMFzgI5na0EZibaei8CgIAy9aoJjrF25eh4NomItwGSubefOcUEh1A3cDeMa9zkWFydADWkVEvJ3Gip7YnmhLQfQCPqEbs2l8Rts5jxfaBxNFkOJ7gL1cH9/xf5jdezM8zKYquDhwdAHGEcskGbanrsHVvTkXWHQ7PPv+S+uZ4vIjJ3V89/u1X+vKw0YbCTMsjHKgobH9qK8IktIFSvDva6782uP3HUXGfkJ/RDX0SfSfrGlMKNx06L6Q1JAlde6KoZPUkTWIx/M8K+gA2fvlsMziJELDtw/ZQi9LSpZCkc3oTD0szI80blzYtIJPNdcC0/wT1WB2obnG5+dkODXUzlQXNYSC8GL76e24iKVvtkuy6BPMsCUg3WFculJGWKLIN6gsbeAGYOIz09TR8ajRM5aFspU459hizTqedNB7PhWK1UROgHuIqsQFPEFs+IeFBkzdlY0LMxXmdRFF+/UYH8kVmQpJd6LxQwzX159L95T9tLqJiNpbT1z4BWEroKWI8z7NdwgeRLJEe94f7KGZIB3yEG476Sx+OeOgJWl4b7FO4WvR5XefRybN8cSY0YWjB2BXeRkKEoqA6atIL++G/zrgrCnZHVc/XeG7LoWRH5E2PYw+qmI7TRDbW5f8HXnsgdtOJWuwAAAAASUVORK5CYII=",
      "text/plain": [
       "<PIL.JpegImagePlugin.JpegImageFile image mode=L size=48x48>"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "angry = list(data_dir.glob('angry/*'))\n",
    "disgust = list(data_dir.glob('disgust/*'))\n",
    "fear = list(data_dir.glob('fear/*'))\n",
    "happy = list(data_dir.glob('happy/*'))\n",
    "neutral = list(data_dir.glob('neutral/*'))\n",
    "sad = list(data_dir.glob('sad/*'))\n",
    "surprise = list(data_dir.glob('surprise/*'))\n",
    "\n",
    "PIL.Image.open(str(angry[0]))\n",
    "# PIL.Image.open(str(fear[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "0955c32a",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 32\n",
    "img_height = 48\n",
    "img_width = 48"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "fa91cd48",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 28709 files belonging to 7 classes.\n",
      "Using 22968 files for training.\n",
      "Found 28709 files belonging to 7 classes.\n",
      "Using 5741 files for validation.\n"
     ]
    }
   ],
   "source": [
    "raw_train_ds = tf.keras.utils.image_dataset_from_directory(\n",
    "  data_dir,\n",
    "  validation_split=0.2,\n",
    "  subset=\"training\",\n",
    "  seed=123,\n",
    "  image_size=(img_height, img_width),\n",
    "  batch_size=None,\n",
    "  color_mode='grayscale')\n",
    "\n",
    "raw_val_ds = tf.keras.utils.image_dataset_from_directory(\n",
    "  data_dir,\n",
    "  validation_split=0.2,\n",
    "  subset=\"validation\",\n",
    "  seed=123,\n",
    "  image_size=(img_height, img_width),\n",
    "  batch_size=None,\n",
    "  color_mode='grayscale')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "1432d4a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['angry', 'disgust', 'fear', 'happy', 'neutral', 'sad', 'surprise']\n"
     ]
    }
   ],
   "source": [
    "# Save class names for later use\n",
    "import json\n",
    "\n",
    "class_names = raw_train_ds.class_names\n",
    "print(class_names)\n",
    "\n",
    "with open('class_names.json', 'w') as f:\n",
    "    json.dump(class_names, f)\n",
    "\n",
    "# To load files\n",
    "def load_class_names():\n",
    "    with open('class_names.json', 'r') as f:\n",
    "        return json.load(f)\n",
    "    \n",
    "num_classes = len(class_names)\n",
    "    \n",
    "# Example usage : predictd_class_name = class_names[predicted_index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "94f677e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Optimization and preprocessing\n",
    "\n",
    "# Optimization\n",
    "AUTOTUNE = tf.data.AUTOTUNE\n",
    "train_ds = raw_train_ds\n",
    "train_ds = train_ds.shuffle(buffer_size=1000)\n",
    "\n",
    "# Cache & Batch & Prefetch\n",
    "tarin_ds = train_ds.cache(filename='my_training_cache')\n",
    "train_ds = train_ds.batch(batch_size)\n",
    "train_ds = train_ds.prefetch(buffer_size=AUTOTUNE)\n",
    "\n",
    "val_ds = raw_val_ds\n",
    "val_ds = val_ds.cache()\n",
    "val_ds = val_ds.batch(batch_size)\n",
    "val_ds = val_ds.prefetch(buffer_size=AUTOTUNE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "c31d3925",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class counts: {'angry': 3995, 'disgust': 436, 'fear': 4097, 'happy': 7215, 'neutral': 4965, 'sad': 4830, 'surprise': 3171}\n",
      "Calculated Class Weight Dictionary: {0: 1.0266046844269623, 1: 9.406618610747051, 2: 1.0010460615781582, 3: 0.5684387684387684, 4: 0.8260394187886635, 5: 0.8491274770777877, 6: 1.293372978330405}\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# 3. Create a dictionary to map class names to their integer index\n",
    "class_indices = {name: i for i, name in enumerate(class_names)}\n",
    "\n",
    "# 4. Count the number of images in each class directory\n",
    "class_counts = {name: len(list(data_dir.joinpath(name).glob('*.jpg'))) for name in class_names}\n",
    "total_samples = sum(class_counts.values())\n",
    "print(f\"Class counts: {class_counts}\")\n",
    "\n",
    "# 5. Calculate the class weights manually\n",
    "class_weight_dict = {}\n",
    "for name, count in class_counts.items():\n",
    "    weight = total_samples / (num_classes * count)\n",
    "    class_index = class_indices[name]\n",
    "    class_weight_dict[class_index] = weight\n",
    "\n",
    "print(\"Calculated Class Weight Dictionary:\", class_weight_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "95d7d542",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_classes = len(class_names)\n",
    "\n",
    "# Data augmentation\n",
    "data_augmentation = tf.keras.Sequential([\n",
    "  tf.keras.layers.RandomFlip(\"horizontal\"),\n",
    "  tf.keras.layers.RandomRotation(0.2),\n",
    "  tf.keras.layers.RandomZoom(0.2),\n",
    "], name=\"data_augmentation\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "af8ea00c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_4\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential_4\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ rescaling_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Rescaling</span>)         │ ?                      │   <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_12 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)              │ ?                      │   <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling2d_12 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>) │ ?                      │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_13 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)              │ ?                      │   <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling2d_13 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>) │ ?                      │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_14 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)              │ ?                      │   <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling2d_14 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>) │ ?                      │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ ?                      │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ flatten_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Flatten</span>)             │ ?                      │   <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_8 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ ?                      │   <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_9 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ ?                      │   <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ rescaling_4 (\u001b[38;5;33mRescaling\u001b[0m)         │ ?                      │   \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_12 (\u001b[38;5;33mConv2D\u001b[0m)              │ ?                      │   \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling2d_12 (\u001b[38;5;33mMaxPooling2D\u001b[0m) │ ?                      │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_13 (\u001b[38;5;33mConv2D\u001b[0m)              │ ?                      │   \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling2d_13 (\u001b[38;5;33mMaxPooling2D\u001b[0m) │ ?                      │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_14 (\u001b[38;5;33mConv2D\u001b[0m)              │ ?                      │   \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling2d_14 (\u001b[38;5;33mMaxPooling2D\u001b[0m) │ ?                      │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_3 (\u001b[38;5;33mDropout\u001b[0m)             │ ?                      │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ flatten_4 (\u001b[38;5;33mFlatten\u001b[0m)             │ ?                      │   \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_8 (\u001b[38;5;33mDense\u001b[0m)                 │ ?                      │   \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_9 (\u001b[38;5;33mDense\u001b[0m)                 │ ?                      │   \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Ancient code for training from scratch - complete sequential without any transfer learning\n",
    "model = tf.keras.Sequential([\n",
    "  tf.keras.layers.Rescaling(1./255),\n",
    "  tf.keras.layers.Conv2D(32, 3, activation='relu'),\n",
    "  tf.keras.layers.MaxPooling2D(),\n",
    "  tf.keras.layers.Conv2D(32, 3, activation='relu'),\n",
    "  tf.keras.layers.MaxPooling2D(),\n",
    "  tf.keras.layers.Conv2D(32, 3, activation='relu'),\n",
    "  tf.keras.layers.MaxPooling2D(),\n",
    "  tf.keras.layers.Dropout(0.4),\n",
    "  tf.keras.layers.Flatten(),\n",
    "  tf.keras.layers.Dense(128, activation='relu'),\n",
    "  tf.keras.layers.Dense(num_classes)\n",
    "])\n",
    "\n",
    "model.compile(\n",
    "  optimizer='adam',\n",
    "  loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "  metrics=['accuracy'])\n",
    "\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "9943d5ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No model weights found at best_CNN_model.keras\n",
      "Starting training from scratch.\n",
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m718/718\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 12ms/step - accuracy: 0.1997 - loss: 1.8808 - val_accuracy: 0.2912 - val_loss: 1.7867\n",
      "Epoch 2/50\n",
      "\u001b[1m718/718\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 6ms/step - accuracy: 0.3139 - loss: 1.7552 - val_accuracy: 0.3555 - val_loss: 1.7074\n",
      "Epoch 3/50\n",
      "\u001b[1m718/718\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 6ms/step - accuracy: 0.3581 - loss: 1.6608 - val_accuracy: 0.4261 - val_loss: 1.5088\n",
      "Epoch 4/50\n",
      "\u001b[1m718/718\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 6ms/step - accuracy: 0.3891 - loss: 1.5907 - val_accuracy: 0.4137 - val_loss: 1.5333\n",
      "Epoch 5/50\n",
      "\u001b[1m718/718\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 7ms/step - accuracy: 0.4104 - loss: 1.5292 - val_accuracy: 0.4576 - val_loss: 1.4356\n",
      "Epoch 6/50\n",
      "\u001b[1m718/718\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 7ms/step - accuracy: 0.4251 - loss: 1.4724 - val_accuracy: 0.4684 - val_loss: 1.4001\n",
      "Epoch 7/50\n",
      "\u001b[1m718/718\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 6ms/step - accuracy: 0.4332 - loss: 1.4334 - val_accuracy: 0.4635 - val_loss: 1.4020\n",
      "Epoch 8/50\n",
      "\u001b[1m718/718\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 6ms/step - accuracy: 0.4444 - loss: 1.4079 - val_accuracy: 0.4647 - val_loss: 1.4213\n",
      "Epoch 9/50\n",
      "\u001b[1m718/718\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 6ms/step - accuracy: 0.4556 - loss: 1.3630 - val_accuracy: 0.4820 - val_loss: 1.3392\n",
      "Epoch 10/50\n",
      "\u001b[1m718/718\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 7ms/step - accuracy: 0.4643 - loss: 1.3342 - val_accuracy: 0.4835 - val_loss: 1.3541\n",
      "Epoch 11/50\n",
      "\u001b[1m718/718\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 7ms/step - accuracy: 0.4711 - loss: 1.3163 - val_accuracy: 0.5001 - val_loss: 1.3071\n",
      "Epoch 12/50\n",
      "\u001b[1m718/718\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 6ms/step - accuracy: 0.4806 - loss: 1.2884 - val_accuracy: 0.4881 - val_loss: 1.3366\n",
      "Epoch 13/50\n",
      "\u001b[1m718/718\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 7ms/step - accuracy: 0.4919 - loss: 1.2542 - val_accuracy: 0.4982 - val_loss: 1.3073\n",
      "Epoch 14/50\n",
      "\u001b[1m718/718\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 6ms/step - accuracy: 0.4985 - loss: 1.2321 - val_accuracy: 0.4874 - val_loss: 1.3264\n",
      "Epoch 15/50\n",
      "\u001b[1m718/718\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 7ms/step - accuracy: 0.5012 - loss: 1.2212 - val_accuracy: 0.5015 - val_loss: 1.3054\n",
      "Epoch 16/50\n",
      "\u001b[1m718/718\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 7ms/step - accuracy: 0.5051 - loss: 1.1970 - val_accuracy: 0.4954 - val_loss: 1.3264\n",
      "Epoch 17/50\n",
      "\u001b[1m718/718\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 7ms/step - accuracy: 0.5165 - loss: 1.1638 - val_accuracy: 0.5137 - val_loss: 1.2789\n",
      "Epoch 18/50\n",
      "\u001b[1m718/718\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 7ms/step - accuracy: 0.5213 - loss: 1.1536 - val_accuracy: 0.5219 - val_loss: 1.2771\n",
      "Epoch 19/50\n",
      "\u001b[1m718/718\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 7ms/step - accuracy: 0.5242 - loss: 1.1403 - val_accuracy: 0.5240 - val_loss: 1.2595\n",
      "Epoch 20/50\n",
      "\u001b[1m718/718\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 7ms/step - accuracy: 0.5304 - loss: 1.1274 - val_accuracy: 0.5149 - val_loss: 1.2690\n",
      "Epoch 21/50\n",
      "\u001b[1m718/718\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 7ms/step - accuracy: 0.5356 - loss: 1.1121 - val_accuracy: 0.5269 - val_loss: 1.2583\n",
      "Epoch 22/50\n",
      "\u001b[1m718/718\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 6ms/step - accuracy: 0.5419 - loss: 1.0926 - val_accuracy: 0.5179 - val_loss: 1.2707\n",
      "Epoch 23/50\n",
      "\u001b[1m718/718\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 7ms/step - accuracy: 0.5437 - loss: 1.0937 - val_accuracy: 0.5132 - val_loss: 1.2778\n",
      "Epoch 24/50\n",
      "\u001b[1m718/718\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 6ms/step - accuracy: 0.5589 - loss: 1.0626 - val_accuracy: 0.5182 - val_loss: 1.2783\n",
      "Epoch 25/50\n",
      "\u001b[1m718/718\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 6ms/step - accuracy: 0.5566 - loss: 1.0606 - val_accuracy: 0.5199 - val_loss: 1.2679\n",
      "Epoch 26/50\n",
      "\u001b[1m718/718\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 7ms/step - accuracy: 0.5589 - loss: 1.0571 - val_accuracy: 0.5226 - val_loss: 1.2542\n",
      "Epoch 27/50\n",
      "\u001b[1m718/718\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 7ms/step - accuracy: 0.5604 - loss: 1.0380 - val_accuracy: 0.5375 - val_loss: 1.2243\n",
      "Epoch 28/50\n",
      "\u001b[1m718/718\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 7ms/step - accuracy: 0.5649 - loss: 1.0357 - val_accuracy: 0.5257 - val_loss: 1.2613\n",
      "Epoch 29/50\n",
      "\u001b[1m718/718\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 7ms/step - accuracy: 0.5782 - loss: 1.0161 - val_accuracy: 0.5224 - val_loss: 1.2632\n",
      "Epoch 30/50\n",
      "\u001b[1m718/718\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 6ms/step - accuracy: 0.5735 - loss: 1.0156 - val_accuracy: 0.5367 - val_loss: 1.2442\n",
      "Epoch 31/50\n",
      "\u001b[1m718/718\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 7ms/step - accuracy: 0.5746 - loss: 0.9994 - val_accuracy: 0.5367 - val_loss: 1.2426\n",
      "Epoch 32/50\n",
      "\u001b[1m718/718\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 6ms/step - accuracy: 0.5850 - loss: 0.9710 - val_accuracy: 0.5271 - val_loss: 1.2540\n",
      "Epoch 32: early stopping\n",
      "Restoring model weights from the end of the best epoch: 27.\n"
     ]
    }
   ],
   "source": [
    "# Model training\n",
    "model_path = 'best_CNN_model.keras'\n",
    "# Implement early stopping\n",
    "early_stopping_callback = tf.keras.callbacks.EarlyStopping(\n",
    "    monitor='val_loss',\n",
    "    patience=5,\n",
    "    verbose=1,\n",
    "    restore_best_weights=True\n",
    ")\n",
    "\n",
    "# Save model periodically\n",
    "model_checkpoint_callback = tf.keras.callbacks.ModelCheckpoint(\n",
    "    filepath=model_path,\n",
    "    save_weights_only=False,\n",
    "    monitor='val_loss',\n",
    "    mode='min',\n",
    "    save_best_only=True,\n",
    ")\n",
    "\n",
    "# Training\n",
    "print(\"No model weights found at\", model_path)\n",
    "print(\"Starting training from scratch.\")\n",
    "history = model.fit(\n",
    "  train_ds,\n",
    "  validation_data=val_ds,\n",
    "  epochs=50,\n",
    "  class_weight=class_weight_dict,\n",
    "  callbacks=[early_stopping_callback, model_checkpoint_callback]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "0c8dfe54",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/jpeg": "/9j/4AAQSkZJRgABAQAAAQABAAD/2wBDAAgGBgcGBQgHBwcJCQgKDBQNDAsLDBkSEw8UHRofHh0aHBwgJC4nICIsIxwcKDcpLDAxNDQ0Hyc5PTgyPC4zNDL/wAALCAAwADABAREA/8QAHwAAAQUBAQEBAQEAAAAAAAAAAAECAwQFBgcICQoL/8QAtRAAAgEDAwIEAwUFBAQAAAF9AQIDAAQRBRIhMUEGE1FhByJxFDKBkaEII0KxwRVS0fAkM2JyggkKFhcYGRolJicoKSo0NTY3ODk6Q0RFRkdISUpTVFVWV1hZWmNkZWZnaGlqc3R1dnd4eXqDhIWGh4iJipKTlJWWl5iZmqKjpKWmp6ipqrKztLW2t7i5usLDxMXGx8jJytLT1NXW19jZ2uHi4+Tl5ufo6erx8vP09fb3+Pn6/9oACAEBAAA/APRviVLLNo9no8TMv9pXIjkI6+WvzEfjwK0tNsorOyhgjQIkaBVUdsCppIwHXjrVadFYNxxXFa9pFvqCSRTRgq3H0ry2Swn0jVnt5Pvocqx/jXsa9614i78f6RbsQ0dvaTzY/uuSoz+VOutVuYAWRbWCLHyNdSEFvfaOQKdpF9cXp8yWa1mTorW5OM/jRq2p22nW+Zd53dSik7friuXXV7K/kCW9zHI/dQefyrl/G9qifY73aA27Zn29K9ims4Trs1zsBnEW3djkA44/SuW8T+FZ9VtrsR3TLJNt2OcnywOwA/P6ip/C+jvpPmyPnGFB564GCfqa5lRPf69Kt7cyrbxu+ApPHXH1/wA9axdPfVHuP+JrZo378qrBMPGueGyK3PFekz6noVqkC+ZJHOCc8Z4r1WaPFzIxH3gOfWq84RULMcL3qqJ45fMjjKbkUFk3DIB9RXEwvCmrujDPmuQDwQT1x9a17mCIQ7lUB8ccVV1ZfK8PNHgmSUrGMepr0S5/1J+tYd9cQQjddSpHCvLM7YHtVS+vLJ7YrKSsbdSyFa5Gzs7C01LzrfYV80uMepHX61tXUwYqB0zWpZ6HBrVvE9zJII4ZPuJwH471uXN6XtpvJjY7WCgnHJ3AEYzkfjWNdraajFLa3dtvRkcSRyAHG3H+IxWZe6hqMMeLYzOimMLuKnhgPX61yJimXxDFcy7YkhLiRYsASHGcMM9uTnH410MsqyXsUEaMCyqcFl4B6d+fwrrdCnaLSrVDAxkm3N8pGMZ5PXtxX//Z",
      "image/png": "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",
      "text/plain": [
       "<PIL.JpegImagePlugin.JpegImageFile image mode=L size=48x48>"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_img_path = fear[20]\n",
    "PIL.Image.open(str(sample_img_path))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "1a9ce9ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 320ms/step\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'_PrefetchDataset' object has no attribute 'class_names'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mAttributeError\u001b[39m                            Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[73]\u001b[39m\u001b[32m, line 15\u001b[39m\n\u001b[32m     12\u001b[39m score = tf.nn.softmax(predictions[\u001b[32m0\u001b[39m])\n\u001b[32m     14\u001b[39m predicted_index = np.argmax(score)\n\u001b[32m---> \u001b[39m\u001b[32m15\u001b[39m predicted_class_name = \u001b[43mtrain_ds\u001b[49m\u001b[43m.\u001b[49m\u001b[43mclass_names\u001b[49m[predicted_index]\n\u001b[32m     17\u001b[39m \u001b[38;5;28mprint\u001b[39m(\n\u001b[32m     18\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mThis image most likely belongs to \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[33m with a \u001b[39m\u001b[38;5;132;01m{:.2f}\u001b[39;00m\u001b[33m percent confidence.\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m     19\u001b[39m     .format(predicted_class_name, \u001b[32m100\u001b[39m * np.max(score))\n\u001b[32m     20\u001b[39m )\n",
      "\u001b[31mAttributeError\u001b[39m: '_PrefetchDataset' object has no attribute 'class_names'"
     ]
    }
   ],
   "source": [
    "\n",
    "img = tf.keras.utils.load_img(\n",
    "    str(sample_img_path),\n",
    "    target_size=(img_width, img_height),\n",
    "    color_mode=\"grayscale\"\n",
    ")\n",
    "\n",
    "# img_array = np.array(img)\n",
    "img_array = tf.keras.utils.img_to_array(img)\n",
    "img_array = np.expand_dims(img_array, 0)  # add batch dimension\n",
    "\n",
    "predictions = model.predict(img_array)\n",
    "score = tf.nn.softmax(predictions[0])\n",
    "\n",
    "predicted_index = np.argmax(score)\n",
    "predicted_class_name = train_ds.class_names[predicted_index]\n",
    "\n",
    "print(\n",
    "    \"This image most likely belongs to {} with a {:.2f} percent confidence.\"\n",
    "    .format(predicted_class_name, 100 * np.max(score))\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90d0819f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
