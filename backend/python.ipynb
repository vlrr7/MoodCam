{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "a0231fd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import PIL\n",
    "import PIL.Image\n",
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "import pathlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "011d8854",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "28709\n"
     ]
    }
   ],
   "source": [
    "data_dir = pathlib.Path('data/train/').with_suffix('')\n",
    "image_count = len(list(data_dir.glob('*/*.jpg')))\n",
    "print(image_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "8a19ce91",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/jpeg": "/9j/4AAQSkZJRgABAQAAAQABAAD/2wBDAAgGBgcGBQgHBwcJCQgKDBQNDAsLDBkSEw8UHRofHh0aHBwgJC4nICIsIxwcKDcpLDAxNDQ0Hyc5PTgyPC4zNDL/wAALCAAwADABAREA/8QAHwAAAQUBAQEBAQEAAAAAAAAAAAECAwQFBgcICQoL/8QAtRAAAgEDAwIEAwUFBAQAAAF9AQIDAAQRBRIhMUEGE1FhByJxFDKBkaEII0KxwRVS0fAkM2JyggkKFhcYGRolJicoKSo0NTY3ODk6Q0RFRkdISUpTVFVWV1hZWmNkZWZnaGlqc3R1dnd4eXqDhIWGh4iJipKTlJWWl5iZmqKjpKWmp6ipqrKztLW2t7i5usLDxMXGx8jJytLT1NXW19jZ2uHi4+Tl5ufo6erx8vP09fb3+Pn6/9oACAEBAAA/APILqyJumd16/Nj1qnLYPw4U/M4UDHU1DcWrW7lWwfmI4/KoirZGRWhYZEiEcMORmu+8LIRFe5BwbdsflXKWHm6pfNEW2ljjJ6CuqtPCcbS27FiziQbjjjvVC/8ACs0kxbZhZAxAx0GSQPyH61W/4RKbc6lPupwffAI/nVKPRZkfJQgdPyODXZeHIQkF2B2gbP5VQ0rRo4dXupAAVIV4yOwNdtpsSFMB1PpzWisUUh/eICV9fcYpk0UC7nESjcR0HU9qyry0gRBGFRM5478nNVtK01dN0m4QD5pC7nPoc4/SsnS2MWpKrjn7pBrrV06AqGzIIj1VWx+R6imrZzLKBFdTtD/DFKwbH44yaVLeYzMZrmTyx1jjwP1xkVWns4UzIXYJnCh2zgepPekt9Usb2ZoraTeF4yVwD9M1zd+HtdcmZUZgrbyFGeK6/Sb6O4tV2srAjg+tXFjeC4Ew/eLjJUEZz+NRQptklmkbblvu56Vl6l5mqF4oQvlAFWLHAPtXPNYXWjOgkhCKWzE6NlWHpn2/rWnBcvNfGeZE3OeD2HtV/wDseZJDNao1uW5YRsCrH1x/hUf2HUY5d4BYnrmUgfWrNppbxyl7mUnPWNGOPzPJrWmjiES+WgUKMYArI1zEmlyKB9zDj2I/+tX/2Q==",
      "image/png": "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",
      "text/plain": [
       "<PIL.JpegImagePlugin.JpegImageFile image mode=L size=48x48>"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "angry = list(data_dir.glob('angry/*'))\n",
    "PIL.Image.open(str(angry[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "0955c32a",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 32\n",
    "img_height = 180\n",
    "img_width = 180"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "fa91cd48",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 28709 files belonging to 7 classes.\n",
      "Using 22968 files for training.\n",
      "Found 28709 files belonging to 7 classes.\n",
      "Using 5741 files for validation.\n"
     ]
    }
   ],
   "source": [
    "train_ds = tf.keras.utils.image_dataset_from_directory(\n",
    "  data_dir,\n",
    "  validation_split=0.2,\n",
    "  subset=\"training\",\n",
    "  seed=123,\n",
    "  image_size=(img_height, img_width),\n",
    "  batch_size=batch_size)\n",
    "\n",
    "val_ds = tf.keras.utils.image_dataset_from_directory(\n",
    "  data_dir,\n",
    "  validation_split=0.2,\n",
    "  subset=\"validation\",\n",
    "  seed=123,\n",
    "  image_size=(img_height, img_width),\n",
    "  batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "b5320823",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0 0.9862875\n"
     ]
    }
   ],
   "source": [
    "normalization_layer = tf.keras.layers.Rescaling(1./255)\n",
    "normalized_ds = train_ds.map(lambda x, y: (normalization_layer(x), y))\n",
    "image_batch, labels_batch = next(iter(normalized_ds))\n",
    "first_image = image_batch[0]\n",
    "# Notice the pixel values are now in `[0,1]`.\n",
    "print(np.min(first_image), np.max(first_image))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "0a3263f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_classes = 7\n",
    "\n",
    "model = tf.keras.Sequential([\n",
    "  tf.keras.layers.Rescaling(1./255),\n",
    "  tf.keras.layers.Conv2D(32, 3, activation='relu'),\n",
    "  tf.keras.layers.MaxPooling2D(),\n",
    "  tf.keras.layers.Conv2D(32, 3, activation='relu'),\n",
    "  tf.keras.layers.MaxPooling2D(),\n",
    "  tf.keras.layers.Conv2D(32, 3, activation='relu'),\n",
    "  tf.keras.layers.MaxPooling2D(),\n",
    "  tf.keras.layers.Flatten(),\n",
    "  tf.keras.layers.Dense(128, activation='relu'),\n",
    "  tf.keras.layers.Dense(num_classes)\n",
    "])\n",
    "\n",
    "model.compile(\n",
    "  optimizer='adam',\n",
    "  loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "  metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9943d5ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n"
     ]
    }
   ],
   "source": [
    "model.fit(\n",
    "  train_ds,\n",
    "  validation_data=val_ds,\n",
    "  epochs=3\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
